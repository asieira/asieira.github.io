<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>InfoSec Zanshin - threat intelligence</title><link href="https://asieira.github.io/" rel="alternate"></link><link href="https://asieira.github.io/feeds/tag_threat-intelligence.atom.xml" rel="self"></link><id>https://asieira.github.io/</id><updated>2016-02-13T02:03:00-02:00</updated><entry><title>Threat Intelligence Indicators are not Signatures</title><link href="https://asieira.github.io/threat-intelligence-indicators-are-not-signatures.html" rel="alternate"></link><published>2016-02-13T02:03:00-02:00</published><updated>2016-02-13T02:03:00-02:00</updated><author><name>Alexandre Sieira</name></author><id>tag:asieira.github.io,2016-02-13:/threat-intelligence-indicators-are-not-signatures.html</id><summary type="html">&lt;p&gt;A common misunderstanding that can lead to a lot of pain.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I have recently participated in a 
&lt;a href="https://www.blackhat.com/html/webcast/01212016-data-driven-threat-intelligence.html"&gt;Black Hat webcast&lt;/a&gt;
with &lt;a href="https://www.twitter.com/bhaskar_vk"&gt;Bhaskar Karambelkar&lt;/a&gt;, which was sponsored by 
&lt;a href="https://threatconnect.com/"&gt;ThreatConnect&lt;/a&gt;. This was related to the Black Hat 2015 session called 
&lt;a href="https://youtu.be/6JMEKnes-w0?list=PLnKLzDQgx6bPRfNuf3sA2Sy2JDjbcg0P5"&gt;Data-Driven Threat Intelligence: Metrics On Indicator Dissemination And Sharing&lt;/a&gt;,
which I had the pleasure to co-present with my good friend &lt;a href="https://twitter.com/alexcpsec"&gt;Alex Pinto&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At the end of the webcast, someone asked me a question about a comment I had made on how threat intelligence indicators
have multiple uses, but should not be used as signatures. One of the audience members was a bit baffled by this, and I 
am sure he is not alone. &lt;/p&gt;
&lt;p&gt;So let's focus on automating the use of simple network indicators (IP addresses, domain names and URLs, mostly) that 
most companies will obtain from public or private threat intelligence feeds. Let me show why &lt;em&gt;using them directly as 
signatures&lt;/em&gt;, such as automatically generating IDS signatures and/or SIEM rules to alert or block on direct matches to 
them, is very troublesome. Organizations that do that will, in my experience, be most likely flooded with false 
positives.&lt;/p&gt;
&lt;p&gt;&lt;img alt="False positives, false positives everywhere!" src="https://asieira.github.io/images/indicators-are-not-signatures/false-positives.png"&gt;&lt;/p&gt;
&lt;p&gt;Let me go over a (far from complete) list of reasons why.&lt;/p&gt;
&lt;h2&gt;Affirming the Consequent Fallacy&lt;/h2&gt;
&lt;p&gt;In order to reliably generate an alert based on network traffic, you need to identify a situation in which the 
probability of that traffic being malicious is reasonably high. How high it needs to be depends on your organization's
tolerance to false positives. So you need to satisfy a requirement &lt;code&gt;P(malicious | traffic) &amp;gt; threshold&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Threat intelligence network indicators are data points that say &lt;em&gt;we observed a threat actor, malware or tool A generate
traffic with the characteristics M, N and O and to the external locations X, Y and Z&lt;/em&gt;. Notice how &lt;strong&gt;that alone does not 
equal any of the following claims&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Most or all of the traffic with characteristics M, N or O to destinations X, Y, Z are caused by A;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A always causes traffic with characteristics M, N or O to destinations X, Y, Z.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Do you notice the mismatch? Most people will erroneously equate the claim &lt;em&gt;attackers do X&lt;/em&gt; to &lt;em&gt;I can safely alert when 
X occurs in my environment&lt;/em&gt;. It's related to the 
&lt;a href="https://en.wikipedia.org/wiki/Affirming_the_consequent"&gt;affirming the consequent fallacy&lt;/a&gt;,
but it's even more striking because the feeds are not even making claim 2 above, which would be required for the classic
form of the fallacy.&lt;/p&gt;
&lt;p&gt;To give you an example, you could find a perfectly valid indicator saying a piece of malware uses something like
a public API from Google, Dropbox or anyone else just to verify whether it can connect to the Internet. Or it could
use some publicly available service to identify which public IP address it is reaching the Internet from, and its 
geolocation, in particular in the case of targeted attacks.&lt;/p&gt;
&lt;p&gt;This sort of indicator can still be really useful if you are doing DFIR or hunting, as it allows you to narrow down 
compromised machines on the network, or let you know which forensic data to investigate first. But it should be obvious 
by now that generating an IDS or SIEM alert for every machine on your network that behaves in a similar manner would be 
a really bad idea.&lt;/p&gt;
&lt;h2&gt;What should I match it against?&lt;/h2&gt;
&lt;p&gt;When you get an intelligence feed, it might contain indicators that are indicative of several different kinds of 
malicious behaviors. In particular the paid feeds will contain a mix of human-readable context in the form a report, 
and also the machine-readable indicators associated  with each report. &lt;/p&gt;
&lt;p&gt;The problem is that it can be very hard to automatically determine in which context each technical indicator can be
applied. In the case of IP addresses, for example, very rarely does the machine-readable data allow you to unambigously
determine something as simple as whether it is associated with &lt;em&gt;inbound&lt;/em&gt; traffic, &lt;em&gt;outbound&lt;/em&gt; traffic or both.&lt;/p&gt;
&lt;p&gt;In case you are not familiar with the terminology, the definition of &lt;em&gt;inbound&lt;/em&gt; and &lt;em&gt;outbound&lt;/em&gt; I'm referring to is the 
one used in &lt;a href="https://github.com/mlsecproject/combine"&gt;combine&lt;/a&gt; and &lt;a href="https://github.com/mlsecproject/tiq-test"&gt;tiq-test&lt;/a&gt;. 
Keeping  your organization as the point of reference, &lt;em&gt;inbound&lt;/em&gt; indicators would refer to traffic originating from the 
open Internet towards your organization's public assets: port scanning, credential brute forcing, automated or manual 
exploitation of Internet-facing services, etc. &lt;em&gt;Outbound&lt;/em&gt; indicators, on the other hand, would be associated with 
traffic originating from inside your organization's network towards the open Internet, such as data exfiltration, C&amp;amp;C 
traffic, downloading of malware or client-side exploits.&lt;/p&gt;
&lt;p&gt;So knowing which traffic &lt;em&gt;direction&lt;/em&gt; each indicator applies to would be the most basic way to reduce false positives,
and it is often not available for use on an automated fashion.&lt;/p&gt;
&lt;h2&gt;"Helpful" Feed Providers&lt;/h2&gt;
&lt;p&gt;Imagine an analyst reverses a new malware or RAT sample and identifies that it uses a particular URL to talk back to
its creator. He will of course generate an indicator in the report for that URL. However, sometimes the feed provider
will go one step further and think "but what about people that want to match this in netflow, firewall or DNS logs?", 
and do you the favor of also generating indicators for:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The hostname of the URL, so you can match this on DNS;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The IP addresses that hostname resolved to at the time of the analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This creates all sort of problems and piles onto the false positives.&lt;/p&gt;
&lt;p&gt;First, extracting the hostname is not always appropriate. Attackers might control the entire content served under that
hostname (think DGAs, a single compromised web server that attacker fully controls). However, it might also be a portal
with completely independent sub-sites hosted under different paths that share no infrastructure except for a load 
balancer that routes requests appropriately. Or it might be something like a Google Drive or Dropbox link, or a URL
shortener. So considering the entire domain to be compromised / malicious because of a few URLs within it is often
a step too far.&lt;/p&gt;
&lt;p&gt;It's even worse when resolving domain names to IP addresses, even for domains completely dedicated to malicious 
purposes. Firstly, we know that miscreants can and will 
&lt;a href="https://en.wikipedia.org/wiki/Fast_flux"&gt;switch the IP addresses a domain resolves to often&lt;/a&gt;, and the IPs you
receive will most likely be outdated by the time you get to use them. Second, it's not uncommon for malicious domains
to be using a service like &lt;a href="https://www.cloudflare.com/"&gt;CloudFlare&lt;/a&gt;, &lt;a href="https://www.incapsula.com/"&gt;Incapsula&lt;/a&gt; or a 
shared hosting service. So if you resolve the domain, you'll get an IP address that's shared with possibly hundreds of
benign websites. Or it could be temporarily parked at a benign IP address such as 8.8.8.8. Again, knowing that a domain 
is malicious does not necessarily mean that all of the IPs it resolves to are mostly or completely malicious as well.&lt;/p&gt;
&lt;p&gt;Feed providers, take note: having this extra information would be more helpful if it was possible to distinguish the 
&lt;em&gt;principled&lt;/em&gt; indicators from the &lt;em&gt;derived&lt;/em&gt; ones. But alas, this information is often not present in the 
computer-readable indicators.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I hope this article helps people realize that organizations need to put proper processes and/or automation in place to 
overcome the problems identified above if they decide to use threat intelligence indicators for detection. Even though 
threat intelligence indicators are really valuable allies to information security monitoring and DFIR initiatives, they 
are not signatures and should be used with appropriate care.&lt;/p&gt;</content><category term="threat intelligence"></category></entry></feed>