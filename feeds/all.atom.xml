<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>InfoSec Zanshin</title><link href="http://asieira.github.io/" rel="alternate"></link><link href="http://asieira.github.io/feeds/all.atom.xml" rel="self"></link><id>http://asieira.github.io/</id><updated>2016-02-13T02:03:00-02:00</updated><entry><title>Threat Intelligence Indicators are not Signatures</title><link href="http://asieira.github.io/threat-intelligence-indicators-are-not-signatures.html" rel="alternate"></link><updated>2016-02-13T02:03:00-02:00</updated><author><name>Alexandre Sieira</name></author><id>tag:asieira.github.io,2016-02-13:threat-intelligence-indicators-are-not-signatures.html</id><summary type="html">&lt;p&gt;I have recently participated in a 
&lt;a href="https://www.blackhat.com/html/webcast/01212016-data-driven-threat-intelligence.html"&gt;Black Hat webcast&lt;/a&gt;
with &lt;a href="https://www.twitter.com/bhaskar_vk"&gt;Bhaskar Karambelkar&lt;/a&gt;, which was sponsored by 
&lt;a href="https://threatconnect.com/"&gt;ThreatConnect&lt;/a&gt;. This was related to the Black Hat 2015 session called 
&lt;a href="https://youtu.be/6JMEKnes-w0?list=PLnKLzDQgx6bPRfNuf3sA2Sy2JDjbcg0P5"&gt;Data-Driven Threat Intelligence: Metrics On Indicator Dissemination And Sharing&lt;/a&gt;,
which I had the pleasure to co-present with my good friend &lt;a href="https://twitter.com/alexcpsec"&gt;Alex Pinto&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At the end of the webcast, someone asked me a question about I point I had made about threat intelligence indicators
having multiple uses, but that they are not signatures. One of the audience members was a bit baffled by this, and I
am sure he is not alone. &lt;/p&gt;
&lt;p&gt;So let's focus on automating the use of simple network indicators (IP addresses, domain names and URLs, mostly) that 
most companies will obtain from public or private threat intelligence feeds. Let me show why &lt;em&gt;using them directly as 
signatures&lt;/em&gt;, such as automatically generating IDS signatures and/or SIEM rules to alert or block on direct matches to 
them, is very troublesome. Organizations that do that will, in my experience, be most likely flooded with false 
positives.&lt;/p&gt;
&lt;p&gt;&lt;img alt="False positives, false positives everywhere!" src="http://asieira.github.io/images/indicators-are-not-signatures/false-positives.png" /&gt;&lt;/p&gt;
&lt;p&gt;Let me go over a (far from complete) list of reasons why.&lt;/p&gt;
&lt;h2&gt;Affirming the Consequent Fallacy&lt;/h2&gt;
&lt;p&gt;In order to reliably generate an alert based on network traffic, you need to identify a situation in which the 
probability of that traffic being malicious is reasonably high. How high it needs to be depends on your organization's
tolerance to false positives. So you need to satisfy a requirement &lt;code&gt;P(malicious | traffic) &amp;gt; threshold&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Threat intelligence network indicators are data points that say &lt;em&gt;we observed a threat actor, malware or tool A generate
traffic with the characteristics M, N and O and to the external locations X, Y and Z&lt;/em&gt;. Notice how &lt;strong&gt;that alone does not 
equal any of the following claims&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Most or all of the traffic with characteristics M, N or O to destinations X, Y, Z are caused by A;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A always causes traffic with characteristics M, N or O to destinations X, Y, Z.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Do you notice the mismatch? Most people will erroneously equate the claim &lt;em&gt;attackers do X&lt;/em&gt; to &lt;em&gt;I can safely alert when 
X occurs in my environment&lt;/em&gt;. It's related to the 
&lt;a href="https://en.wikipedia.org/wiki/Affirming_the_consequent"&gt;affirming the consequent fallacy&lt;/a&gt;,
but it's even more striking because the feeds are not even making claim 2 above, which would be required for the classic
form of the fallacy.&lt;/p&gt;
&lt;p&gt;To give you an example, you could find a perfectly valid indicator saying a piece of malware uses something like
a public API from Google, Dropbox or anyone else just to verify whether it can connect to the Internet. Or it could
one some publicly available service to identify which public IP address it is reaching the Internet from, and its 
geolocation, in particular in the case of targeted attacks.&lt;/p&gt;
&lt;p&gt;This sort of indicator can still be really useful if you are doing DFIR or hunting, as it allows you to narrow down 
compromised machines on the network, or let you know which forensic data to investigate first. But it should be obvious 
by now that generating an IDS or SIEM alert for every machine on your network that behaves in a similar manner would be 
a really bad idea.&lt;/p&gt;
&lt;h2&gt;What should I match it against?&lt;/h2&gt;
&lt;p&gt;When you get an intelligence feed, it might contain indicators that are indicative of several different kinds of 
malicious behaviors. In particular the paid feeds will contain a mix of human-readable context in the form a report, 
and also the machine-readable indicators associated  with each report. &lt;/p&gt;
&lt;p&gt;The problem is that it can be very hard to automatically determine in which context each technical indicator can be
applied. In the case of IP addresses, for example, very rarely does the machine-readable data allow you to unambigously
determine something as simple as whether it is associated with &lt;em&gt;inbound&lt;/em&gt; traffic, &lt;em&gt;outbound&lt;/em&gt; traffic or both.&lt;/p&gt;
&lt;p&gt;In case you are not familiar with the terminology, the definition of &lt;em&gt;inbound&lt;/em&gt; and &lt;em&gt;outbound&lt;/em&gt; I'm referring to is the 
one used in &lt;a href="https://github.com/mlsecproject/combine"&gt;combine&lt;/a&gt; and &lt;a href="https://github.com/mlsecproject/tiq-test"&gt;tiq-test&lt;/a&gt;. 
Keeping  your organization as the point of reference, &lt;em&gt;inbound&lt;/em&gt; indicators would refer to traffic originating from the 
open Internet towards your organization's public assets: port scanning, credential brute forcing, automated or manual 
exploitation of Internet-facing services, etc. &lt;em&gt;Outbound&lt;/em&gt; indicators, on the other hand, would be associated with 
traffic originating from inside your organization's network towards the open Internet, such as data exfiltration, C&amp;amp;C 
traffic, downloading of malware or client-side exploits.&lt;/p&gt;
&lt;p&gt;So knowing which traffic &lt;em&gt;direction&lt;/em&gt; each indicator applies to would be the most basic way to reduce false positives,
and it is often not available for use on an automated fashion.&lt;/p&gt;
&lt;h2&gt;"Helpful" Feed Providers&lt;/h2&gt;
&lt;p&gt;Imagine an analyst reverses a new malware or RAT sample and identifies that it uses a particular URL to talk back to
its creator. He will of course generate an indicator in the report for that URL. However, sometimes the feed provider
will go one step further and think "but what about people that want to match this in netflow, firewall or DNS logs?", 
and do you the favor of also generating indicators for:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;The hostname of the URL, so you can match this on DNS;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The IP addresses that hostname resolved to at the time of the analysis.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This creates all sort of problems and piles onto the false positives.&lt;/p&gt;
&lt;p&gt;First, extracting the hostname is not always appropriate. Attackers might control the entire content served under that
hostname (think DGAs, a single compromised web server that attacker fully controls). However, it might also be a portal
with completely independent sub-sites hosted under different paths that share no infrastructure except for a load 
balancer that routes requests appropriately. Or it might be something like a Google Drive or Dropbox link, or a URL
shortener. So considering the entire domain to be compromised / malicious because of a few URLs within it is often
a step too far.&lt;/p&gt;
&lt;p&gt;It's even worse when resolving domain names to IP addresses, even for domains completely dedicated to malicious 
purposes. Firstly, we know that miscreants can and will 
&lt;a href="https://en.wikipedia.org/wiki/Fast_flux"&gt;switch the IP addresses a domain resolves to often&lt;/a&gt;, and the IPs you
receive will most likely be outdated by the time you get to use them. Second, it's not uncommon for malicious domains
to be using a service like &lt;a href="https://www.cloudflare.com/"&gt;CloudFlare&lt;/a&gt;, &lt;a href="https://www.incapsula.com/"&gt;Incapsula&lt;/a&gt; or a 
some shared hosting service. So if you resolve the domain, you'll get an IP address that's shared with possibly hundreds
of benign websites. Or it could be temporarily parked at a benign IP address such as 8.8.8.8. Again, knowing that a 
domain is malicious does not necessarily mean that all of the IPs it resolves to are mostly or completely malicious as
well.&lt;/p&gt;
&lt;p&gt;Feed providers, take note: having this extra information would be more helpful if it was possible to distinguish the 
&lt;em&gt;principled&lt;/em&gt; indicators from the &lt;em&gt;derived&lt;/em&gt; ones. But alas, this information is often not present in the 
computer-readable indicators.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I hope this article helps people realize that organizations need to put proper processes and/or automation in place to 
overcome the problems identified above if they decide to use threat intelligence indicators for detection. Even though 
threat intelligence indicators are really valuable allies to information security monitoring and DFIR initiatives, they 
are not signatures and should be used with appropriate care.&lt;/p&gt;</summary><category term="threat intelligence"></category></entry><entry><title>Test Data to Develop Splunk Content</title><link href="http://asieira.github.io/test-data-to-develop-splunk-content.html" rel="alternate"></link><updated>2016-02-02T17:40:00-02:00</updated><author><name>Alexandre Sieira</name></author><id>tag:asieira.github.io,2016-02-02:test-data-to-develop-splunk-content.html</id><summary type="html">&lt;p&gt;&lt;a href="http://splunk.com"&gt;Splunk&lt;/a&gt; is the SIEM platform I have been working the most with recently. It is a joy to work with 
because it has embraced the development paradigm, and organizes standard and user-developed content into apps. And it 
lets you write code in proper languages like Python or Java to process the data in ways that go beyond their own query 
language.&lt;/p&gt;
&lt;p&gt;Which brings me to how it is that you can develop and test an app for security devices and environments you don't 
personally have access to. Actual sample log data is not easy to come by. And even if you do find it some Splunk apps 
expect the log data to be ingested in particular ways (e.g. syslog), and replaying them from a file on disk is not 
always trivial. &lt;/p&gt;
&lt;p&gt;This is a concern both if you are writing a new app that will be used by others, or if you want to ensure that your
internal organization's apps are able to correctly handle log entries that are infrequent or that you might not
have encountered before. For example, the 
&lt;a href="https://docs.splunk.com/Documentation/CIM/latest/User/IntrusionDetection"&gt;Network Intrusion CIM model&lt;/a&gt;
does not specify a finite list of possible values for the &lt;code&gt;action&lt;/code&gt; field. And until you see some test examples you
won't know that the Check Point OPSEC TA field extractions will have the service name instead of the port number in the 
&lt;code&gt;dest_port&lt;/code&gt; field of the 
&lt;a href="https://docs.splunk.com/Documentation/CIM/latest/User/NetworkTraffic"&gt;Network Traffic CIM model&lt;/a&gt;. So you'll need to 
get a representative set of events and find what out values the TAs actually generate if you want to ensure your content 
will adequately survive its first encounter with with real events out there in the wilderness.&lt;/p&gt;
&lt;p&gt;Looking into this for the &lt;a href="https://splunkbase.splunk.com/app/2777/"&gt;Niddel app&lt;/a&gt; I stumbled upon a very useful tool 
called &lt;a href="https://github.com/splunk/eventgen"&gt;eventgen&lt;/a&gt;. Basically what I have found is that most Splunk-developed apps,
and many developed by third parties, are shipped with configurations that allow you to easily generate sample log data 
that you can then use to test your content. &lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/splunk/eventgen/blob/develop/README/Tutorial.md"&gt;eventgen tutorial&lt;/a&gt; is very thorough and the
tool is very well documented. However the documentation is almost exclusively focused on app developers which want to
support event generation in their apps. Very little is said about how to simply use the functionality the app developers
already built-in. So let me try to help fill in the gaps here with the TL;DR version, which I only recommend for
development-only Splunk instances:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;First, confirm if the particular app or TA you are interested in has that configuration: go to its directory
under &lt;code&gt;$SPLUNK_HOME/etc/apps&lt;/code&gt; (or download it from &lt;a href="https://splunkbase.splunk.com"&gt;SplunkBase&lt;/a&gt; and check within the 
archive) for a &lt;code&gt;samples&lt;/code&gt; directory and a &lt;code&gt;default/eventgen.conf&lt;/code&gt; file. If it's there, you're in luck.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Then, ensure that the apps or TA for which you want to generate events os configured to share their content globally, 
or the eventgen app (installed later) won't be able to access its sample data and configurations. The simplest way to 
do this is on Splunk Web is to navigate to &lt;code&gt;Apps&lt;/code&gt; -&amp;gt; &lt;code&gt;Manage Apps&lt;/code&gt; and click on &lt;code&gt;Permissions&lt;/code&gt; under the &lt;code&gt;Sharing&lt;/code&gt; column
for the app you want events from. Make sure the &lt;code&gt;Sharing for config file-only objects&lt;/code&gt; option is set to &lt;code&gt;All apps&lt;/code&gt;: 
&lt;img alt="Splunk app permissions" src="http://asieira.github.io/images/splunk-test-data/app-permissions.png" /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Download the &lt;a href="https://github.com/splunk/eventgen/"&gt;eventgen GitHub repository&lt;/a&gt; as a 
&lt;a href="https://github.com/splunk/eventgen/archive/develop.zip"&gt;ZIP file&lt;/a&gt; and install it as a Splunk app in &lt;code&gt;Apps&lt;/code&gt; -&amp;gt; 
&lt;code&gt;Manage Apps&lt;/code&gt; -&amp;gt; &lt;code&gt;Install app from file&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The new eventgen app does not have a setup page when you go to it under &lt;code&gt;Apps&lt;/code&gt;, just statistics on the generated events.
So the only way I found to enable and disable it is to go to &lt;code&gt;Apps&lt;/code&gt; -&amp;gt; &lt;code&gt;Manage Apps&lt;/code&gt; and click on &lt;code&gt;Set Up&lt;/code&gt; on the row of
the eventgen app. Mark and unmark the &lt;code&gt;Enable ./bin/eventgen.py&lt;/code&gt; checkbox to enable/disable event generation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once this is done, eventgen will inspect all other installed apps it can access (hence the permissions step above) and
generate fake events for them according to their configurations, usually directly to the &lt;code&gt;main&lt;/code&gt; index. No easy way to
choose which apps to generate events from at this time, unfortunately.&lt;/p&gt;</summary><category term="splunk"></category><category term="siem"></category></entry></feed>